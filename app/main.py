from langchain_aws.chat_models.bedrock import ChatBedrock
import os
from dotenv import load_dotenv
from langchain.prompts import (
    PromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
    ChatPromptTemplate,
)
import json
from langchain_core.output_parsers import JsonOutputParser

load_dotenv()

AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')
AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')
AWS_SESSION_TOKEN = os.getenv('AWS_SESSION_TOKEN')
inference_profile = "us.anthropic.claude-3-5-sonnet-20240620-v1:0" 
region_name = "us-east-1" 

llm = ChatBedrock( model_id=inference_profile, 
                  region_name=region_name, 
                  aws_access_key_id=AWS_ACCESS_KEY_ID, 
                  aws_secret_access_key=AWS_SECRET_ACCESS_KEY, 
                  aws_session_token=AWS_SESSION_TOKEN) 


# system_message = SystemMessagePromptTemplate(
#         prompt=PromptTemplate(template=system_prompt_template, input_variables=[])
#     )


# response = llm.invoke("what is an LLM ?") 
# print(response.content)

def generate_structured_story(story_arc: str) -> dict:
    """
    Generates a story in a structured format using a Bedrock LLM via a LangChain chain.

    This function builds a chain that:
    1. Takes a system prompt to define the task and output format.
    2. Takes a human prompt (the user's storsy arc).
    3. Sends the combined prompt to the LLM.
    4. Parses the LLM's JSON string output into a Python dictionary.

    Args:
        story_arc: The user's desired story line or concept.

    Returns:
        A dictionary containing the structured story generated by the LLM.
    """
    # 1. Define the System Prompt Template
    # This sets the context and instructions for the LLM.
    system_prompt_template = """
    You are an intelligent system that creates stories for user based on the user's story arc.
    The Output must be in JSON format. And follow the given example.
    ### Example
    Input : Ria embarked on an adventure in the forest & discover a hidden treasure
    Output : {{
        "title" : "The adventure of Ria",
        "characters" : "Ria, Treasure Gaurdian",
        "setting" : "Forest",
        "story" : "Once upon a time, a princess named ria left her kingdom in searhc of a treasure which would bring prosperity to her kingdom. One day in a forest, Ria saw a strange glow in the pond nearby, and out of curiosity ria approached it & suddenly a gaurdian rose from the water. He asked ria to solve a puzzle, upon solving gaurdian gifted ria with treasure. Ria came back to kingdom and helped her people with the treasure she discovered."
    }}
    """
    system_message = SystemMessagePromptTemplate(
        prompt=PromptTemplate(template=system_prompt_template, input_variables=[])
    )

    human_template = "{story_arc}"
    human_message = HumanMessagePromptTemplate.from_template(human_template)
    chat_prompt = ChatPromptTemplate.from_messages([system_message, human_message])
    parser = JsonOutputParser()
    chain = chat_prompt | llm | parser
    print("Invoking LLM chain...")
    response = chain.invoke({"story_arc": story_arc})
    print("Received response.")

    return response




if __name__ == '__main__':
    # Example of how to run the script directly
    user_story_arc = "A lonely lighthouse keeper discovers a mysterious glowing pearl that washes ashore."
    try:
        story = generate_structured_story(user_story_arc)
        print("\n--- Generated Story ---")
        print(json.dumps(story, indent=2))
        print("---------------------\n")
    except Exception as e:
        print(f"\nAn error occurred: {e}")
        print("Please ensure your AWS credentials and model configurations are correct.")
